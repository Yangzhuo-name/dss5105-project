# parameter_tuning/score_analyzer.py
"""
åˆ†æ•°åˆ†å¸ƒåˆ†æå·¥å…·
åœ¨è¿›è¡Œç½‘æ ¼æœç´¢å‰ï¼Œå…ˆåˆ†æå½“å‰ç³»ç»Ÿçš„åˆ†æ•°åˆ†å¸ƒç‰¹å¾
è¿™æ ·å¯ä»¥æ›´æœ‰é’ˆå¯¹æ€§åœ°è®¾ç½®é˜ˆå€¼èŒƒå›´

è¿è¡Œæ–¹å¼ï¼š
python parameter_tuning/score_analyzer.py
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.retriever import search
import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')

# æµ‹è¯•ç”¨ä¾‹
TEST_CASES = {
    "High": [
        "When is my rent due each month?",
        "What is the security deposit amount?",
        "Who pays for electricity and water?",
        "What's the diplomatic clause?",
        "Who is responsible for air conditioning maintenance?",
        "Can I keep pets?",
        "Who pays for repairs under $200?",
    ],
    
    "Medium": [
        "Can I paint the walls?",
        "What happens if I want to install a washing machine?",
        "Can I hang pictures on the wall?",
        "What if I need to break the lease due to job loss?",
    ],
    
    "Low": [
        "How do I negotiate a rent reduction?",
        "What's the average rent in this area?",
        "Can I get a tax deduction for my rent?",
        "Which moving company do you recommend?",
        "How do I apply for a housing loan?",
    ]
}


def analyze_score_distribution():
    """åˆ†æåˆ†æ•°åˆ†å¸ƒ"""
    print("\n" + "="*80)
    print("ğŸ“Š åˆ†æ•°åˆ†å¸ƒåˆ†æ")
    print("="*80)
    print("ç›®çš„: äº†è§£ä¸åŒç±»åˆ«é—®é¢˜çš„æ£€ç´¢åˆ†æ•°åˆ†å¸ƒï¼Œä¸ºé˜ˆå€¼è®¾ç½®æä¾›ä¾æ®\n")
    
    pdf_path = "./data/tenancy_agreement.pdf"
    
    # æ”¶é›†æ‰€æœ‰åˆ†æ•°
    score_data = {
        "High": [],
        "Medium": [],
        "Low": []
    }
    
    detailed_results = []
    
    print("ğŸ” æ­£åœ¨æ£€ç´¢æ‰€æœ‰æµ‹è¯•é—®é¢˜...")
    for expected_confidence, questions in TEST_CASES.items():
        print(f"\nå¤„ç† {expected_confidence} ç±»åˆ«...")
        for question in questions:
            try:
                results = search(
                    question,
                    top_k=5,
                    with_scores=True,
                    active_pdf_path=pdf_path
                )
                
                if results:
                    top_score = results[0].metadata.get('score', 1.0)
                    score_data[expected_confidence].append(top_score)
                    
                    # è®¡ç®—åˆ†æ•°å·®è·
                    gap = 0
                    if len(results) >= 2:
                        gap = results[1].metadata.get('score', 1.0) - top_score
                    
                    detailed_results.append({
                        'question': question,
                        'expected_class': expected_confidence,
                        'top_score': top_score,
                        'score_gap': gap,
                        'top5_scores': [r.metadata.get('score', 1.0) for r in results[:5]]
                    })
                    
                    print(f"  âœ“ {question[:50]}... â†’ {top_score:.3f}")
                else:
                    print(f"  âœ— {question[:50]}... â†’ æ— ç»“æœ")
                    
            except Exception as e:
                print(f"  âœ— {question[:50]}... â†’ é”™è¯¯: {str(e)}")
    
    # ç»Ÿè®¡åˆ†æ
    print("\n" + "="*80)
    print("ğŸ“ˆ ç»Ÿè®¡ç»“æœ")
    print("="*80)
    
    statistics = {}
    for cls, scores in score_data.items():
        if scores:
            statistics[cls] = {
                'min': float(np.min(scores)),
                'max': float(np.max(scores)),
                'mean': float(np.mean(scores)),
                'median': float(np.median(scores)),
                'std': float(np.std(scores)),
                'q25': float(np.percentile(scores, 25)),
                'q75': float(np.percentile(scores, 75)),
                'count': len(scores)
            }
            
            print(f"\nã€{cls}ç±»åˆ«ã€‘ï¼ˆ{len(scores)}ä¸ªé—®é¢˜ï¼‰")
            print(f"  æœ€å°å€¼: {statistics[cls]['min']:.3f}")
            print(f"  25åˆ†ä½: {statistics[cls]['q25']:.3f}")
            print(f"  ä¸­ä½æ•°: {statistics[cls]['median']:.3f}")
            print(f"  å¹³å‡å€¼: {statistics[cls]['mean']:.3f}")
            print(f"  75åˆ†ä½: {statistics[cls]['q75']:.3f}")
            print(f"  æœ€å¤§å€¼: {statistics[cls]['max']:.3f}")
            print(f"  æ ‡å‡†å·®: {statistics[cls]['std']:.3f}")
    
    # æ¨èé˜ˆå€¼
    print("\n" + "="*80)
    print("ğŸ’¡ é˜ˆå€¼æ¨è")
    print("="*80)
    
    if score_data['High'] and score_data['Medium']:
        # åŸºäºæ•°æ®æ¨èé˜ˆå€¼
        high_max = statistics['High']['max']
        medium_min = statistics['Medium']['min']
        medium_max = statistics['Medium']['max']
        
        # æ¨èç­–ç•¥ï¼š
        # HIGHé˜ˆå€¼ = Highç±»åˆ«çš„75åˆ†ä½ + 10%å®‰å…¨è¾¹é™…
        # MEDIUMé˜ˆå€¼ = Mediumç±»åˆ«çš„75åˆ†ä½ + 10%å®‰å…¨è¾¹é™…
        
        recommended_high = statistics['High']['q75'] * 1.1
        recommended_medium = statistics['Medium']['q75'] * 1.1
        
        print(f"\nåŸºäºæ•°æ®åˆ†å¸ƒçš„æ¨èå€¼:")
        print(f"  THRESHOLD_HIGH:   {recommended_high:.3f}")
        print(f"  THRESHOLD_MEDIUM: {recommended_medium:.3f}")
        
        print(f"\nè¯´æ˜:")
        print(f"  - Highç±»åˆ«æœ€å¤§å€¼: {high_max:.3f}")
        print(f"  - Mediumç±»åˆ«èŒƒå›´: {medium_min:.3f} - {medium_max:.3f}")
        print(f"  - æ¨èHIGHé˜ˆå€¼è¦†ç›–äº†{statistics['High']['q75']}åˆ†ä½çš„Highé—®é¢˜")
        print(f"  - æ¨èMEDIUMé˜ˆå€¼è¦†ç›–äº†{statistics['Medium']['q75']}åˆ†ä½çš„Mediumé—®é¢˜")
    
    # åˆ†æåˆ†æ•°å·®è·
    print("\n" + "="*80)
    print("ğŸ“ åˆ†æ•°å·®è·åˆ†æ")
    print("="*80)
    
    gaps = [r['score_gap'] for r in detailed_results if r['score_gap'] > 0]
    if gaps:
        print(f"\nåˆ†æ•°å·®è·ç»Ÿè®¡:")
        print(f"  å¹³å‡å·®è·: {np.mean(gaps):.3f}")
        print(f"  ä¸­ä½å·®è·: {np.median(gaps):.3f}")
        print(f"  æœ€å°å·®è·: {np.min(gaps):.3f}")
        print(f"  æœ€å¤§å·®è·: {np.max(gaps):.3f}")
        
        # æ¨ègapé˜ˆå€¼
        recommended_gap = float(np.percentile(gaps, 25))  # 25åˆ†ä½ä½œä¸ºé˜ˆå€¼
        print(f"\næ¨è SCORE_GAP_THRESHOLD: {recommended_gap:.3f}")
        print(f"  ï¼ˆå½“å·®è·å°äºæ­¤å€¼æ—¶ï¼Œè§†ä¸ºæ¨¡ç³Šç»“æœï¼‰")
    
    # ç”Ÿæˆå¯è§†åŒ–
    print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    _create_visualization(score_data, statistics, detailed_results)
    
    # ä¿å­˜ç»“æœ
    output = {
        'analysis_time': str(np.datetime64('now')),
        'statistics': statistics,
        'detailed_results': detailed_results,
        'recommended_thresholds': {
            'threshold_high': float(recommended_high) if 'recommended_high' in locals() else None,
            'threshold_medium': float(recommended_medium) if 'recommended_medium' in locals() else None,
            'score_gap_threshold': float(recommended_gap) if 'recommended_gap' in locals() else None
        }
    }
    
    output_file = 'parameter_tuning/score_analysis.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜: {output_file}")
    
    return output


def _create_visualization(score_data, statistics, detailed_results):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('æ£€ç´¢åˆ†æ•°åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')
    
    # 1. ç®±çº¿å›¾
    ax1 = axes[0, 0]
    data_to_plot = [score_data['High'], score_data['Medium'], score_data['Low']]
    labels = ['High', 'Medium', 'Low']
    colors = ['#51cf66', '#ffd43b', '#ff6b6b']
    
    bp = ax1.boxplot(data_to_plot, labels=labels, patch_artist=True)
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.6)
    
    ax1.set_ylabel('æ£€ç´¢åˆ†æ•°', fontsize=12)
    ax1.set_title('åˆ†æ•°åˆ†å¸ƒç®±çº¿å›¾', fontsize=14, fontweight='bold')
    ax1.grid(axis='y', alpha=0.3)
    
    # 2. ç›´æ–¹å›¾
    ax2 = axes[0, 1]
    for cls, scores in score_data.items():
        if scores:
            ax2.hist(scores, bins=20, alpha=0.5, label=cls)
    
    ax2.set_xlabel('æ£€ç´¢åˆ†æ•°', fontsize=12)
    ax2.set_ylabel('é¢‘æ•°', fontsize=12)
    ax2.set_title('åˆ†æ•°åˆ†å¸ƒç›´æ–¹å›¾', fontsize=14, fontweight='bold')
    ax2.legend()
    ax2.grid(alpha=0.3)
    
    # 3. æ•£ç‚¹å›¾
    ax3 = axes[1, 0]
    for cls, color in zip(['High', 'Medium', 'Low'], colors):
        cls_data = [r for r in detailed_results if r['expected_class'] == cls]
        scores = [r['top_score'] for r in cls_data]
        gaps = [r['score_gap'] for r in cls_data]
        ax3.scatter(scores, gaps, alpha=0.6, label=cls, color=color, s=100)
    
    ax3.set_xlabel('Top-1 åˆ†æ•°', fontsize=12)
    ax3.set_ylabel('åˆ†æ•°å·®è· (Top2-Top1)', fontsize=12)
    ax3.set_title('åˆ†æ•° vs å·®è·', fontsize=14, fontweight='bold')
    ax3.legend()
    ax3.grid(alpha=0.3)
    
    # 4. ç»Ÿè®¡è¡¨æ ¼
    ax4 = axes[1, 1]
    ax4.axis('off')
    
    table_data = []
    table_data.append(['ç±»åˆ«', 'æœ€å°', 'ä¸­ä½', 'å¹³å‡', 'æœ€å¤§'])
    for cls in ['High', 'Medium', 'Low']:
        if cls in statistics:
            s = statistics[cls]
            table_data.append([
                cls,
                f"{s['min']:.3f}",
                f"{s['median']:.3f}",
                f"{s['mean']:.3f}",
                f"{s['max']:.3f}"
            ])
    
    table = ax4.table(cellText=table_data, cellLoc='center',
                     loc='center', bbox=[0, 0.3, 1, 0.6])
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)
    
    # è®¾ç½®è¡¨å¤´æ ·å¼
    for i in range(5):
        table[(0, i)].set_facecolor('#e9ecef')
        table[(0, i)].set_text_props(weight='bold')
    
    ax4.set_title('ç»Ÿè®¡æ‘˜è¦', fontsize=14, fontweight='bold', pad=20)
    
    plt.tight_layout()
    output_file = 'parameter_tuning/score_distribution.png'
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {output_file}")


if __name__ == "__main__":
    print("\nğŸ” å¼€å§‹åˆ†ææ£€ç´¢åˆ†æ•°åˆ†å¸ƒ...")
    result = analyze_score_distribution()
    print("\nâœ… åˆ†æå®Œæˆï¼")
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨: parameter_tuning/score_distribution.png")
    print("  2. æ ¹æ®æ¨èé˜ˆå€¼è¿è¡Œç½‘æ ¼æœç´¢: python parameter_tuning/grid_search.py --quick")