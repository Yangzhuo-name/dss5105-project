# test_benchmark.py
"""
Benchmarkæµ‹è¯•ï¼šéªŒè¯é¡¹ç›®è¦æ±‚çš„3ä¸ªæ ‡å‡†é—®é¢˜
ç›®æ ‡ï¼šæ‰€æœ‰é—®é¢˜éƒ½åº”è¯¥è¾¾åˆ°High confidence
"""

from src.chat import ask
import json
from datetime import datetime

# é¡¹ç›®è¦æ±‚çš„3ä¸ªbenchmarké—®é¢˜
BENCHMARK_QUESTIONS = [
    "What's the diplomatic clause?",
    "When things are spoiled/broken, who pays to repair?",
    "What to do before returning the unit?",
]

def test_benchmark():
    """æµ‹è¯•benchmarké—®é¢˜"""
    print("="*80)
    print("BENCHMARK VALIDATION TEST")
    print("="*80)
    print(f"Test Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Total Questions: {len(BENCHMARK_QUESTIONS)}")
    print("="*80)
    
    results = []
    passed = 0
    
    for i, question in enumerate(BENCHMARK_QUESTIONS, 1):
        print(f"\n{'='*80}")
        print(f"Question {i}: {question}")
        print("="*80)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        response = ask(question)
        
        # æå–ä¿¡æ¯
        confidence = response.get('confidence', 'Unknown')
        score = response.get('score', 0.0)
        has_reference = response.get('reference') is not None
        answer = response.get('answer', '')
        
        # åˆ¤æ–­æ˜¯å¦é€šè¿‡
        is_pass = confidence == "High"
        
        if is_pass:
            passed += 1
            status = "âœ… PASS"
        else:
            status = "âŒ FAIL"
        
        print(f"\nStatus: {status}")
        print(f"Confidence: {confidence}")
        print(f"Score: {score:.4f}")
        print(f"Has Reference: {'Yes' if has_reference else 'No'}")
        
        if has_reference:
            ref_page = response['reference'].get('page', '?')
            print(f"Reference Page: {ref_page}")
        
        print(f"\nAnswer Preview:")
        print(f"{answer[:200]}...")
        
        # ä¿å­˜ç»“æœ
        results.append({
            'question': question,
            'confidence': confidence,
            'score': score,
            'has_reference': has_reference,
            'passed': is_pass,
            'answer': answer
        })
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("SUMMARY")
    print("="*80)
    
    print(f"\nTotal Questions: {len(BENCHMARK_QUESTIONS)}")
    print(f"Passed: {passed}/{len(BENCHMARK_QUESTIONS)}")
    print(f"Pass Rate: {passed/len(BENCHMARK_QUESTIONS)*100:.1f}%")
    
    if passed == len(BENCHMARK_QUESTIONS):
        print("\nğŸ‰ All benchmark questions passed!")
    else:
        print(f"\nâš ï¸  {len(BENCHMARK_QUESTIONS) - passed} question(s) failed")
        print("\nFailed questions:")
        for r in results:
            if not r['passed']:
                print(f"  â€¢ {r['question']}")
                print(f"    Got: {r['confidence']} (expected: High)")
    
    # ä¿å­˜ç»“æœ
    output = {
        'test_time': datetime.now().isoformat(),
        'total': len(BENCHMARK_QUESTIONS),
        'passed': passed,
        'pass_rate': passed/len(BENCHMARK_QUESTIONS),
        'results': results
    }
    
    with open('benchmark_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print("\n" + "="*80)
    print(f"Results saved to: benchmark_test_results.json")
    print("="*80)
    
    return results


if __name__ == "__main__":
    test_benchmark()